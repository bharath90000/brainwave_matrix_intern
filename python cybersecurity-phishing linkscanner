import re
import requests
from urllib.parse import urlparse

#list of suspicious keywords
suspicious_keywords = ["login", "verify", " update", "password", "secure", "account"
                       ,"webscr","support","banking","security", "signin"]

def is_it_suspicious_url(url):
    ip_pattern = re.compile(r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b')
    if ip_pattern.search(url):
        return True, "URL contains an IP address, which is often suspicious."

    # check for common phishing related keywords
    for keyword in suspicious_keywords:
        if keyword in url.lower():
            return True, f"URL contains a suspicious keyword: {keyword}"

    # check if URL is long ( a possible red flag)
    if len(url) > 100:
        return True, "URL is unusually long, which looks suspicious."
    return False, "URL looks perfect based on basic checks."
#url from user as input
url = input( " enter the URL you want to scan:")


def check_url_response(URL):
    try:
        response = requests.head(URL, allow_redirects=True, timeout=5)
        if response.status_code in [301, 302]:
            return True, "URL redirects to another site, which triggers suspiciousness."
        elif response.status_code >= 400:
            return True, f"URL returned a status code {response.status_code}, which indicates issue."
        else:
            return False, "URL responded with a normal status code."
    except requests.exceptions.RequestException as e:
        return True, f"Error connecting to URL: {str(e)}"
#perform basic url structure checks
def scan_url(url):
        suspicious, reason = is_it_suspicious_url(url)
        if suspicious:
            print(f"warning: {reason}")
        else:
            print(" fundamentals passed.")

# Further check the URL by attempting to connect
suspicious, reason = check_url_response(url)
if suspicious:
    print(f"Warning: {reason}")
else:
    print("url seems trustful.")


